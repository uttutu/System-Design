Database Sharding
Overview

Database sharding is a horizontal partitioning technique used to improve the scalability, performance, and availability of large databases.
In sharding, data is split across multiple independent databases (called shards) â€” each holding a subset of the data.
This approach allows systems to handle larger datasets and higher throughput by distributing load instead of relying on a single database instance.

Why Sharding Is Needed

As systems scale, a single database may hit its limits in:

ğŸ’¾ Storage capacity â€“ the dataset becomes too large to fit on one node.

âš™ï¸ Throughput â€“ read/write operations exceed what one server can handle.

ğŸ•“ Latency â€“ performance degrades due to large indexes or I/O bottlenecks.

ğŸ§© Maintenance â€“ backups, migrations, and schema changes become slow.

Sharding helps by splitting data horizontally, enabling parallelism and scaling out linearly with the number of shards.

Key Concepts
Concept	Description
Shard	A physical database that holds a subset of data.
Shard Key	The attribute used to determine which shard a record belongs to (e.g., user_id, region).
Shard Map / Routing Layer	Service or logic responsible for directing queries to the correct shard.
Resharding	The process of redistributing data when shards are added, removed, or rebalanced.
Sharding Strategies
1. Range-Based Sharding

Data is divided based on value ranges of a shard key (e.g., users 1â€“1M in shard A, 1Mâ€“2M in shard B).

âœ… Pros: Easy to implement; efficient range queries.

âš ï¸ Cons: Risk of hotspots if data is unevenly distributed.

2. Hash-Based Sharding

A hash function is applied to the shard key to evenly distribute data across shards.

âœ… Pros: Even data distribution; good for write-heavy workloads.

âš ï¸ Cons: Range queries become difficult.

3. Directory-Based Sharding

A lookup table maintains mappings between keys and shards.

âœ… Pros: Maximum flexibility for data placement.

âš ï¸ Cons: Directory can become a bottleneck or single point of failure.

4. Geo-Sharding (Regional Sharding)

Data is partitioned based on user geography or region.

âœ… Pros: Reduces latency and complies with data residency requirements.

âš ï¸ Cons: Complex failover and inter-region queries.

Sharding Architecture

A typical sharded setup involves:

Application Layer â€” Determines the shard key for each query.

Routing Layer / Middleware â€” Routes requests to the correct shard (e.g., Vitess, Citus, or custom logic).

Shard Databases â€” Individual instances, each storing a subset of data.

Metadata Store â€” Maintains the shard map and configuration metadata.

Challenges in Sharding

ğŸ”„ Rebalancing: Adding or removing shards requires data migration.

ğŸ” Cross-Shard Queries: Joins or aggregations across shards are complex and slow.

ğŸ’¥ Transaction Management: Maintaining ACID properties across shards is non-trivial.

ğŸ“‹ Schema Changes: Must be applied consistently across all shards.

ğŸ§  Operational Complexity: Monitoring, backups, and scaling strategies multiply per shard.

Best Practices

Choose a stable shard key that avoids hotspots.

Keep shard boundaries immutable to prevent rebalancing churn.

Use a routing middleware (like ProxySQL, Vitess, or Citus) for query routing.

Automate resharding and monitoring processes.

Maintain metadata consistency and shard maps under version control.

Plan for growth â€” avoid fixed shard counts that limit scalability.

Real-World Examples

ğŸ§± YouTube / Vitess: Uses sharding to scale MySQL horizontally.

ğŸ“¦ Amazon: Shards by customer or region for high isolation.

ğŸ’¬ Discord: Shards user sessions and messages for performance.

ğŸµ Spotify: Combines sharding with caching for distributed playlists.

Common Pitfalls

Uneven data distribution due to poor shard key selection.

Ignoring the cost of cross-shard joins and transactions.

Centralized routing logic becoming a bottleneck.

Lack of tooling for shard management and observability.

Sharding vs. Partitioning
Aspect	Sharding	Partitioning
Scope	Distributed across multiple nodes	Within a single database instance
Goal	Scale out horizontally	Improve manageability/performance
Management	Application-level or middleware	Database-level (e.g., PostgreSQL partitions)
Further Reading

Vitess: Scaling MySQL for YouTube

Citus Data Sharding in PostgreSQL

Google Cloud Spanner Architecture

[Designing Data-Intensive Applications â€“ Martin Kleppmann (Chapter on Partitioning)]
